---
title: Pond（ASPLOS 23）
date: 2023-11-28 12:52:57
description: Pond（ASPLOS 23）论文阅读
tags:
- CXL
- 分层
- 论文阅读
categories:
- Memory
---

内存池化有望提高 DRAM 利用率，这对公有云有很大的吸引力；但内存池化可能对性能造成伤害，因为远端内存的访问延时大于本地内存的访问延时。

Pond 是一个建立在 CXL 标准之上的内存池系统，显著降低 DRAM 成本且满足云性能目标。

# Introduction

**动机。**许多公有云客户以虚拟机（VM）的形式部署 workloads，这给公有云提供商带来了一个重大挑战：如何以具有性价比的硬件成本为不透明的虚拟机（无法查看客户在虚拟机中运行的内容）实现高性能。

内存是影响性能和成本的关键因素。内存成本非常高，占微软 Azure 和 Meta 服务器成本的 40% 和 50%；然而，在 Azure 生产环境下，**内存搁浅**（一台服务器上 CPU 核心已经全部租给虚拟机使用，但存在部分未分配的内存容量。从云服务提供商的角度看就是 CPU 售尽了，内存没售尽）非常严重，且是内存浪费的主要原因；此外，已分配给虚拟机的内存未必被充分利用，比如虚拟机共有 8GB 内存，但是最多只使用了 6GB，那么如果剩余 2GB 全部来自池内存，也不会影响性能。

**现有最优技术的局限性。**现有的进程级内存压缩技术需要页中断，这会增加微妙延迟，且不再静态分配内存；内存分解可以池化内存，将搁浅的内存返回到内存池中供其它服务器使用，但是，现有的分离内存也具有微秒级访问延迟，并且需要页中断或对 VM guest 进行修改。

**Insights**

1. 分析了 Azure 100 个生产集群的跟踪，相比同一 NUMA 上的内存访问，CXL 技术使得 8-16 插槽大小（能够使用该内存池的 CPU 插槽数量）的内存池增加 70-90 ns，使得机架级大小的内存池增加 180 ns 延迟。而 8-16 个插槽的池大小可以节省足够的 DRAM；

    - 在 CPU 资源利用率高的集群中，未分配搁浅内存的比例可高达 25%；

        {% asset_img memory_stranding.jpg memory_stranding %}

2. 对于 Azure 上的典型 158 工作负载，分析它们在 CXL 内存相比于在本地内存中运行时产生的性能损失。发现（1）40% 左右的工作负载性能损失在 5% 以内；（2）21% 的工作负载遭遇了超过 25% 的性能损失。说明**部分工作负载对内存延迟不敏感，可以完全分配 CXL 内存，而对于延迟敏感的内存，可以配置本地和 CXL 混合内存**。

    {% asset_img local_and_cxl.jpg local_and_cxl %}

    {% asset_img cxl_slowdown.jpg cxl_slowdown %}

3. 对于已分配给虚拟机的内存，50% 的虚拟机占用的租用内存不足 50%，此时，即使**未使用的内存全部来自内存池也不会影响延迟敏感的虚拟机**。如果将池内存作为 zero-core 虚拟 NUMA（zNUMA）节点暴漏给虚拟机的操作系统，这个结论确实成立。

4. 如果可以正确预测（1）一个虚拟机是否延迟敏感，（2）虚拟机未使用的内存大小，则分配的 CXL 内存具有和同一 NUMA 上的内存相同的性能；对于失败的预测，引入一种新颖的监视系统，如果检测到内存性能不佳便触发缓存措施，将虚拟机迁移为仅使用同一 NUMA 节点内存。

基于以上 insights，Pond 通过 ML 模型预测虚拟机是否延迟敏感以及未使用的内存大小，静态分配同一 NUMA 节点内存和动态分配池内存，并通过监视系统检测性能，性能不佳时进行适当迁移。

# Design

**设计目标。**

1. 高性能。在采用访问速度相对较慢的外部 CXL 内存后，虚拟机的性能应该与完全使用本地 NUMA 上的 DRAM 性能接近；
2. 硬件兼容性。与虚拟化加速器兼容；
3. 软件兼容性。与不透明的虚拟机和客户应用程序相兼容；
4. 低开销。额外开销尽可能小。

## 池内存大小

作者发现最多可以有 16 个 CPU sockets 可以直接与 EMC（external memory controller） 相连，而如果大于 16，则需要加入 CXL 交换机，这会显著增加内存池的访问延迟和硬件成本。

{% asset_img EMC.jpg EMC %}

{% asset_img pool_size_latency.jpg pool_size_latency %}

此外，作者发现当池大小大于 16 时，收益明显递减。因此，8/16 的池大小是性能和成本的平衡点。

{% asset_img pool_size_impact.jpg pool_size_impact %}

## 混合内存分配

当需要分配一个虚拟机时，首先使用 ML 模型预测需要为虚拟机分配多少本地内存，再通过调度程序将目标主机及其池内存需求信息告知池管理器，池管理器触发内存在线工作流程，调度程序通知虚拟机管理程序在与内存量匹配的 zNUMA 节点上启动虚拟机。

{% asset_img pond_control_plane.jpg pond_control_plane %}

## 预测模型

首先检查当前请求的虚拟机是否可以和工作负载历史相关联，具体实现方式是通过检查过去的虚拟机是否具有与请求虚拟机相同的元数据（例如客户 ID，虚拟机类型和位置）。如果有过去的工作负载历史记录，便预测该虚拟机是否对内存延迟敏感（比如全使用池内存相比于全使用本地内存，性能下降在 5% 以内可以被视为不敏感）；如果虚拟机没有工作负载历史记录或预计对延迟敏感，再预测其未使用的内存容量，对应部分使用池内存分配。

与此同时，在虚拟机运行过程中监视其性能，如果使用到了池内存，则需要进行虚拟机迁移，重新进行内存分配。

{% asset_img prediction_models.jpg prediction_models %}

## 实现

使用 NUMA 模拟。在具有两个 sockets 的服务器上只使用一个 socket，而在另一个 socket 上禁用所有 CPU 核心，模拟成 CXL 内存池。

